{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326b7c2a",
   "metadata": {},
   "source": [
    "This is the shortened version of the work in class2.ipynb - for more notes on functions and piple check that document or exercises 1 nad 2 from class 2 of the NLP course https://minaalmasi.github.io/nlp-at-cogsci/main/class2_intro.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f034f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/ucloud/.local/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ucloud/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089e8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/ucloud/.local/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/ucloud/.local/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/ucloud/.local/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ucloud/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ucloud/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3cff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "#Import BOW vectorizer for preprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Import TF-IDF vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1336c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of notebook\n",
    "path = Path.cwd()\n",
    "\n",
    "data_path = path.parents[1] / \"resources\" / \"data\" / \"raid\" / \"train_none.csv\"\n",
    "\n",
    "raw_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline without function\n",
    "df = raw_df[raw_df[\"model\"].isin([\"human\", \"cohere\"])]\n",
    "\n",
    "df[\"is_human\"] = df[\"model\"].apply(lambda x: 1 if x == \"human\" else 0)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify= df['is_human'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff99ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasplitter(raw_df, model_a, model_b, positive_class,\n",
    "                 test_size, random_state):\n",
    "    \"\"\"\n",
    "    Subset dataframe by two chosen models, create binary column based on\n",
    "    positive_class, and split into train and validation sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_df : pandas.DataFrame\n",
    "        The original dataframe containing at least a 'model' column.\n",
    "    model_a, model_b : str\n",
    "        The two models to include in the subset.\n",
    "    positive_class : str\n",
    "        The model label that should be encoded as 1 in the binary column.\n",
    "    test_size : float\n",
    "        Proportion of validation set (default 0.2).\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    train_df : pandas.DataFrame\n",
    "    val_df   : pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset\n",
    "    df = raw_df[raw_df[\"model\"].isin([model_a, model_b])].copy()\n",
    "    \n",
    "    # Binary column\n",
    "    binary_col = f\"is_{positive_class.lower()}\"\n",
    "    df[binary_col] = df[\"model\"].apply(lambda x: 1 if x == positive_class else 0)\n",
    "    \n",
    "    # Split\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=df[binary_col]\n",
    "    )\n",
    "    \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a0694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = datasplitter(raw_df, \"human\", \"chatgpt\", \"human\", 0.2, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316dfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal \n",
    "# using Literal is not strictly necessary, \n",
    "# but is a way to define the options that you can use for the function!\n",
    "\n",
    "def vectorize(X_train: pd.Series, X_val: pd.Series, vec_type:Literal[\"bow\", \"tf-idf\"], max_features:int=500):\n",
    "    \"\"\"\n",
    "    Function to vectorize train and val data! \n",
    "    \"\"\"\n",
    "    if vec_type == \"bow\":\n",
    "        vectorizer = CountVectorizer(lowercase=True, max_features=max_features)\n",
    "    elif vec_type== \"tf-idf\":\n",
    "        vectorizer = TfidfVectorizer(lowercase=True, max_features=max_features)\n",
    "    else: \n",
    "        # this is good code practice, but if your function has no 'else' statement, this is also fine!\n",
    "        raise ValueError(f\"Invalid vec_type: {vec_type}. Must be either 'bow' or 'tf-idf\")\n",
    "    \n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "    return X_train_vectorized, X_val_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4315df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY TO GET TF-IDF\n",
    "X_train_tfidf, X_val_tfidf = vectorize(\n",
    "                        X_train = train_df[\"generation\"], \n",
    "                          X_val = val_df[\"generation\"],\n",
    "                          vec_type=\"tf-idf\",\n",
    "                          max_features=500\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0581804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf is common naming convention\n",
    "clf = LogisticRegression(\n",
    "    random_state=42,\n",
    "    solver=\"liblinear\",   # tested all solvers, and this one was fastest ... (should also be appropriate for our data)\n",
    "    max_iter=1000,        # allow more iterations\n",
    "    C=1.0,                # adjust if needed (smaller values = stronger regularization)\n",
    ")\n",
    "\n",
    "#Let’s extract our numerical labels as Y:\n",
    "\n",
    "y_train = train_df[\"is_human\"]\n",
    "\n",
    "#Let’s fit our classifier on our vectorized text X_train_bow and our y_train:\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Let’s extract predicted labels y:\n",
    "\n",
    "y_pred_tfidf = clf.predict(X_val_tfidf)\n",
    "\n",
    "#Now, we can compare to our actual labels y val:\n",
    "\n",
    "y_val_tfidf = val_df[\"is_human\"]\n",
    "report_tfidf = classification_report(y_val_tfidf, y_pred_tfidf)\n",
    "print(report_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafeea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function needs some work: I want to just pass a data frame and then it can extract y values itself\n",
    "\n",
    "def classifier(X_train, y_train, X_val, y_val, model_name,\n",
    "                               random_state, solver,\n",
    "                               max_iter, C, verbose=True):\n",
    "    \"\"\"\n",
    "    Train logistic regression, predict on validation data, \n",
    "    and print classification report.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : training data + labels\n",
    "    X_val, y_val     : validation data + labels\n",
    "    random_state     : int, seed\n",
    "    solver           : str, optimizer\n",
    "    max_iter         : int, max iterations\n",
    "    C                : float, inverse regularization strength\n",
    "    verbose          : bool, whether to print report\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    clf   : trained LogisticRegression model\n",
    "    y_pred: predicted labels for validation set\n",
    "    report: classification report (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train\n",
    "    model_name = LogisticRegression(\n",
    "        random_state=random_state,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        C=C\n",
    "    )\n",
    "    model_name.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model_name.predict(X_val)\n",
    "    \n",
    "    # Report\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    if verbose:\n",
    "        print(report)\n",
    "    \n",
    "    return model_name, y_pred, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ead277c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80      5349\n",
      "           1       0.14      0.00      0.00      2674\n",
      "\n",
      "    accuracy                           0.67      8023\n",
      "   macro avg       0.40      0.50      0.40      8023\n",
      "weighted avg       0.49      0.67      0.53      8023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df[\"is_human\"]\n",
    "\n",
    "y_val_tfidf = val_df[\"is_human\"]\n",
    "\n",
    "clf, y_pred, report = classifier(X_train_tfidf, y_train, X_val_tfidf, y_val_tfidf, clf, 52, \"liblinear\", 1000, 1.0 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
